<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-6TYYNWJEG4"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-6TYYNWJEG4');
  </script>
 
  <title>Zhuoming Chen</title>
  
  <meta name="author" content="Zhuoming Chen">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">
	
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Zhuoming Chen ÈôàÂçìÊòé</name>
              </p>
              <p>
		I am a first-year Ph.D. student at <a href="https://www.ri.cmu.edu">Carnegie Mellon University</a> advised by Prof. <a href="https://www.andrew.cmu.edu/user/beidic/">Beidi Chen</a> and Prof. <a href="https://www.cs.cmu.edu/~zhihaoj2/">Zhihao Jia</a>. 
		Prior to this, I pursued my undergraduate studies in Automation at <a href="https://www.tsinghua.edu.cn/en/">Tsinghua University</a>, 
		where I had the privilege of working alongside Prof. <a href="https://pacman.cs.tsinghua.edu.cn/~zjd/">Jidong Zhai</a>. 
		I also gained research experience under the guidance of Prof. <a href="https://alchem.cs.purdue.edu/xuehaiq.html">Xuehai Qian</a> at Purdue University.
	      </p>
              <p style="text-align:center">
                <a href="mailto:chenzhuoming911@gmail.com">Email</a> &nbsp/&nbsp
                <a href="data/resume.pdf">CV</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=4Bb5KRYAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <a href="https://github.com/WentseChen">Github</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/Zhuoming.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/Zhuoming.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>
                My research interests lie in deep reinforcement learning, multi-agent reinforcement learning and robotics, 
		with the goal of robots being able to collaborate, explore and learn like human beings.
              </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
				
		  
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/openrl.png' width="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://github.com/OpenRL-Lab/openrl">
                <papertitle>OpenRL: an open-source reinforcement learning research framework</papertitle>
              </a>
		
              <br>
	      Shiyu Huang, 
              <b>Wentse Chen</b>, 
              Yiwen Sun, 
	      Fuqing Bie, 
	      Wei-Wei Tu
              <br>
	      
	      <iframe src="https://ghbtns.com/github-btn.html?user=OpenRL-Lab&repo=openrl&type=star&count=true" frameborder="0" scrolling="0" width="170" height="30" title="GitHub"></iframe>
              <p></p>
              <p>
		      Supports single-agent and multi-agent RL algorithms, natural language tasks(RLHF), self-play training.
              </p>
            </td>
          </tr>			
		  
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/Spread(easy).gif' width="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2207.05631">
                <papertitle>DGPO: Discovering Multiple Strategies with Diversity-Guided Policy Optimization</papertitle>
              </a>
		    
              <br>
              <b>Wentse Chen</b>, 
              Shiyu Huang, 
              Yuan Chiang, 
	      Tim Pearce,
	      Wei-Wei Tu,
	      Chen Ting, 
              Zhu Jun,
              <br>
              <em>The 38th Annual AAAI Conference on Artificial Intelligence (AAAI2024)</em> 
              <p></p>
              <p>
                Proposed an on-policy framework for discovering multiple strategies for the same task in a single training process.
              </p>
            </td>
          </tr>

	<tr>
            <td rowspan="2" style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/tikick.gif' width="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2302.07515">
                <papertitle>TiZero: Mastering Multi-Agent Football with Curriculum Learning and Self-Play</papertitle>
              </a>
	      <br> 
              Fanqi Lin*, 
	      Shiyu Huang*,
	      Tim Pearce,
              <b>Wentse Chen</b>,
              Wei-Wei Tu
              <br>
	      <em>The 22nd International Conference on Autonomous Agents and Multiagent Systems(AAMAS2023)</em>
              <p></p>
              <p>
		      Created an on-policy MARL algorithm, along with an adaptive curriculum learning approach and a unique self-play strategy, for excelling in the Google Research Football game.
              </p>
            </td>
          </tr>	
		
	<tr>
	    <!-- <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/tikick.gif' width="160">
              </div>
            </td> -->
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2110.04507">
                <papertitle>TiKick: Towards Playing Multi-agent Football Full Games from Single-agent Demonstrations</papertitle>
              </a>
	      <br> 
              Shiyu Huang*, 
              <b>Wentse Chen*</b>,
              Longfei Zhang, 
	      Shizhen Xu, 
	      Ziyang Li, 
	      Fengming Zhu, 
	      Deheng Ye, 
	      Ting Chen, 
	      Jun Zhu
              <br>
	      <em>NeurIPS-21 Workshop: 2nd Offline Reinforcement Learning Workshop</em>
              <p></p>
              <p>
                Developed a distributed learning system and new offline algorithms to learn a powerful multi-agent AI from the fixed single-agent dataset.
              </p>
            </td>
          </tr>		
        
        </tbody></table>
	
	<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
		<tr>
			<td style="padding:0px">
			<p style="text-align:right;font-size:small;">
			last update: Dec 30, 2023
			</p>
			</td>
		</tr>
		<tr>
			<td style="padding:0px">
			<p style="text-align:right;font-size:small;">
			Copy from <a href="https://jonbarron.info/">Dr. Jon Barron</a>'s page.
			</p>
			</td>
		</tr>
	</tbody></table>	
</body>

</html>
